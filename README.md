# Survey of Distributions

looking at relationships between distributions.

the code for the site can be found [here](https://github.com/robillersomeone/robillersomeone.github.io).

typos are normally distributed, so if you see one please let me know.

## Continuous Distributions
the starting point is the gamma in theory and code in `distributions.py`, due to the point of reference the gamma serves for other distributions.

the graphing code can be found in the viz directory, all graphs are of the probability density function for the given distribution over a subset of their support, normally [0, 20)

### normal distribution
two parameters
- mean (`Œº` location parameter)
- variance (`œÉ^2` scale parameter)

### gamma distribution and special cases (Pearson type III)
two parameters
- shape (`k`, positive real numbers)
- scale (`Œ∏`, positive real numbers, `Œ≤` the inverse scale - 'rate' can also be used where `Œ≤=1/Œ∏`)

known as maximum entropy distribution
for processes with waiting times between events... like the waiting time between poisson distributed events

two constructions
- using exponentials and the gamma function for positive integers:
`Œì(k) = (k ‚àí 1)!`
- using the improper integral from `[0,‚àû)` for complex numbers
    - this is used to build the distributions that follow

<img src="./imgs/gamma_distributions.png" height="300px" width="400px">

### erlang is a case of gamma
two parameters
- shape (`k` positive **integer**)
- rate (`Œª` positive real number, 'scale' - reciprocal of rate (`1/Œª`) can also be used)

**in relation to gamma** it's the gamma distribution with the shape parameter as an integer

the sum of `k` independent exponentially distributed random variables with mean `Œ∏`
thought of as probability distribution of waiting time until `k-th` arrival.

in relation to chi-squared, it's a chi-squared distribution with 2k degrees of freedom, when `scale=2` ~ generalized chi-squared distribution

the scale parameterization is implemented in `distributions.py` 

<img src="./imgs/erlang_distribution_9_1.png" height="300px" width="400px">

### exponential distribution (Pearson type III)
one parameter
- rate (`Œª` over the interval ``[0,‚àû)``)

**in relation to gamma**
- as an Erlang distribution with the shape parameter 'fixed' as `k=1`
  - the sum of `k` exponential distributions is an Erlang distribution with `(k,Œª)`
  - by extension, as a gamma distribution
- as the probability distribution of time between events of a poisson distribution
- backwards, `n` independent and identically distributed  exponential distributions random variables  sum to a gamma distribution with shape `n` and rate `Œª`

in relation to discrete distributions it's the continuous case of the geometric

has a memoryless property - past is not helpful in predicting the future.

<img src="./imgs/exponential_distribution_1.png" height="300px" width="400px">

### chi-squared distribution (Pearson type III)
one parameter
- degrees of freedom (`k`, the sum of the squared of independent standard normal distributions)

**in relation to gamma** chi-squared is a special case of the gamma distribution with `ŒΩ` degrees of freedom, where `gamma(ŒΩ/2 ,2) = œá2(ŒΩ)`

used in hypothesis testing, as goodness of fit and independence.

<img src="./imgs/chi_squared_distribution_3.png" height="300px" width="400px">

### beta distribution (Pearson type I)
two parameters
- shape (`ùõº`)
- shape (`Œ≤`)

'distribution over distributions', defining binomial coefficient for continuous variables


**in relation to gamma** is a gamma distribution divided by the sum of that gamma distribution with another, which takes the form `gamma(1) / (gamma(1) + gamma(2))`

 the beta function is the product of two iid gamma functions divided by the sum of the two random variables in a gamma function.

 <img src="./imgs/beta_distribution_2_5.png" height="300px" width="400px">

### f-distribution (Pearson type VI)
two parameters
- degrees of freedom in numerator (`n`, positive integer)
- degrees of freedom in denominator (`m`, positive integer)

**in relation to gamma** f-distribution is the ratio of two chi squared distributions (where the chi-squared is a special case of the gamma distribution)

used to model ratio of sample variances, for Analysis Of Variance (ANOVA) and regression

f-distribution is also a specific parameterization of the beta prime distribution (inverted beta distribution)

used in f-test in hypothesis testing. null hypothesis ~ two independent normal variances are equal.

in the code, it's built with the gamma function tranforming the sums of the degrees of freedom as well as the individual degrees of freedom - all divided by 2, the f-distribution can be thought of as two the chi-squared parameterizations of the gamma distribution.

<img src="./imgs/f_distributions.png" height="300px" width="400px">

### normal distribution
two parameters
- location (`Œº` mean parameter)
- scale (`œÉ^2` variance parameter)


as the 'shape' parameter increases (for large `k`, or a `k -> ‚àû`) the gamma distribution converges to the normal distribution

**in relation to gamma** using the central limit theorem, the gamma (or any distribution with finite variance) will converge to the normal distribution

<img src="./imgs/approximated_normal_distribution_25.png" height="300px" width="400px">

### t-distribution (Pearson type VII)
one parameters
- degrees of freedom `ùúà`

**in relation to the gamma** the probability density function is given by the gamma function with the degrees of freedom


arises from sampling, estimate the mean of a normally distributed population
- sample size is small
- population standard deviation is unknown



### cauchy distribution (Pearson type IV)
two parameters
- location (`x` where `x` is real)
- scale (`Œ≥` where `Œ≥ > 0`)

two independent standard normal divided by one another

cauchy distribution has no mean, variance, or higher moments defined.
The mode and median are defined and equal to the location parameter.

`cauchy(0,1)` is a student's t with 1 degree of freedom `t(df=1)`, this is also called the standard cauchy distribution

### dirichlet distribution
two parameters
- categories (`k`, where `k` is a integer ‚â• 2)
- concentration (`ùõº`, where `ùõº > 0`)

domain ~ thought of as a set of probability distrubtions

**in relation to gamma** the gamma distribution can generate random vectors that form a dirichlet distribution
- `k` independently distributed gamma distributions, each divided by `V` (the sum of the `k` distributions)


multivariate generalization of beta distribution
can be thought of as 'a distribution over distributions'
  - sampling from a dirichlet results in a distribution

symmetric dirichlet distributions - where all parameters are equal.

concentration parameter ~ how concentrated the proabability mass of from the distribution is likely to be
  - with value less than 1 the mass is concentrated in a few components.
  - value greater than 1 the mass is dispersed ~ equal in components.

## Discrete Distributions
starting with the negative binomial distribution, due to relationship with gamma


### negative binomial
parameters
 - number of failures ('r' where `r > 0`)
 - probability of success (`p`, for each experiment)


number of successes in a sequence of independent and identically distributed (iid) **Bernoulli** trials before `r` failures

can view the negative binomial as **poisson** distribution with `Œª` being a random variable with a gamma distribution with shape `r` and scale `Œ∏ = p/(1-p)`

under certain parameters the negative binomial converges to the poisson

## To add

### Pearson distributions
four continuous distributions

type I ~ generalized beta distribtuion

type II ~ symmetric type I distributions

type III ~ generalized gamma distribution ~ chi-squared

type IV ~ cauchy distribution

type V ~ inverse gamma distribution

type VI ~ f-distribution or a beta prime

type VII ~ t-distribution


getting normal ~ take the limit of a I, III, IV, V, or VI distribution.
### Tweedie distribution





## Sources

[wiki list of distribitions](https://en.wikipedia.org/wiki/List_of_probability_distributions)
